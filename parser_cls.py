import asyncio
import html
import json
import random
import time
import urllib3
from urllib.parse import unquote, urlparse, parse_qs, urlencode, urlunparse
from bs4 import BeautifulSoup
from curl_cffi import requests
from curl_cffi.requests import RequestsError
from loguru import logger
from pydantic import ValidationError
from requests.cookies import RequestsCookieJar
from common_data import HEADERS
from dto import Proxy, AvitoConfig
from get_cookies import get_cookies
from load_config import load_avito_config
from models import ItemsResponse, Item
from avito_db import AvitoDB
from price_manager import check_and_update_prices
from init_ads import init_db_from_config

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

DEBUG_MODE = False

logger.add("logs/app.log", rotation="5 MB", retention="10 days", level="DEBUG")


class AvitoParse:
    def __init__(
            self,
            config: AvitoConfig,
            stop_event=None
    ):
        self.config = config
        self.mobile_proxies = self._load_mobile_proxies()
        self.current_proxy_index = 0
        self.proxy_obj = self.get_current_proxy_obj()
        self.stop_event = stop_event
        self.cookies = None
        self.session = requests.Session()
        # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π —Å–º–µ–Ω—ã IP
        self.requests_count = 0
        self.max_requests_per_ip = getattr(config, 'proxy_max_requests_per_rotation', 20)
        self.failed_requests_count = 0  # –°—á–µ—Ç—á–∏–∫ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–¥—Ä—è–¥
        self.proxy_requests_count = 0  # –°—á–µ—Ç—á–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–æ–∫—Å–∏
        self.db = AvitoDB()

    def _load_mobile_proxies(self) -> list:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–µ –º–æ–±–∏–ª—å–Ω—ã–µ –ø—Ä–æ–∫—Å–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞"""
        if hasattr(self.config, 'mobile_proxies') and self.config.mobile_proxies:
            active_proxies = [proxy for proxy in self.config.mobile_proxies if proxy.active]
            if active_proxies:
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(active_proxies)} –∞–∫—Ç–∏–≤–Ω—ã—Ö –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏")
                return active_proxies
        
        # Fallback –∫ —Å—Ç–∞—Ä–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        if all([self.config.proxy_string, self.config.proxy_change_url]):
            from dto import MobileProxy
            fallback_proxy = MobileProxy(
                proxy_string=self.config.proxy_string,
                proxy_change_url=self.config.proxy_change_url,
                name="Legacy Proxy",
                active=True
            )
            logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è legacy –ø—Ä–æ–∫—Å–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è")
            return [fallback_proxy]
        
        logger.warning("–ú–æ–±–∏–ª—å–Ω—ã–µ –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã")
        return []

    def get_current_proxy_obj(self) -> Proxy | None:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–æ–∫—Å–∏"""
        if not self.mobile_proxies:
            logger.info("–†–∞–±–æ—Ç–∞–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏")
            return None
            
        current_proxy = self.mobile_proxies[self.current_proxy_index]
        return Proxy(
            proxy_string=current_proxy.proxy_string,
            change_ip_link=current_proxy.proxy_change_url
        )

    def rotate_proxy(self) -> bool:
        """–ü–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –ø—Ä–æ–∫—Å–∏ –≤ —Å–ø–∏—Å–∫–µ"""
        if len(self.mobile_proxies) <= 1:
            return False
            
        old_index = self.current_proxy_index
        
        # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ —Ä–æ—Ç–∞—Ü–∏–∏
        rotation_mode = getattr(self.config, 'proxy_rotation_mode', 'round_robin')
        
        if rotation_mode == 'random':
            # –°–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä (–∏—Å–∫–ª—é—á–∞—è —Ç–µ–∫—É—â–∏–π)
            available_indices = [i for i in range(len(self.mobile_proxies)) if i != self.current_proxy_index]
            if available_indices:
                self.current_proxy_index = random.choice(available_indices)
        else:  # round_robin (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
            self.current_proxy_index = (self.current_proxy_index + 1) % len(self.mobile_proxies)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—ä–µ–∫—Ç –ø—Ä–æ–∫—Å–∏
        self.proxy_obj = self.get_current_proxy_obj()
        self.proxy_requests_count = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–∫—Å–∏
        
        current_proxy = self.mobile_proxies[self.current_proxy_index]
        logger.info(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∏–ª–∏—Å—å —Å –ø—Ä–æ–∫—Å–∏ #{old_index} –Ω–∞ –ø—Ä–æ–∫—Å–∏ #{self.current_proxy_index} ({current_proxy.name})")
        
        return True


    def get_proxy_obj(self) -> Proxy | None:
        """Deprecated: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ get_current_proxy_obj()"""
        return self.get_current_proxy_obj()

    def get_cookies(self, max_retries: int = 5, delay: float = 2.0) -> dict | None:
        return None
        for attempt in range(1, max_retries + 1):
            try:
                # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ cookies –≤ –Ω–æ–≤–æ–º event loop
                cookies = asyncio.run(get_cookies(proxy=self.proxy_obj, headless=True))
                if cookies and isinstance(cookies, dict) and len(cookies) > 0:
                    logger.info(f"[get_cookies] –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω—ã cookies —Å –ø–æ–ø—ã—Ç–∫–∏ {attempt}")
                    return cookies
                else:
                    raise ValueError("–ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç cookies –∏–ª–∏ –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç")
            except Exception as e:
                logger.warning(f"[get_cookies] –ü–æ–ø—ã—Ç–∫–∞ {attempt} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
                if attempt < max_retries:
                    logger.info(f"[get_cookies] –û–∂–∏–¥–∞–Ω–∏–µ {delay * attempt} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π...")
                    time.sleep(delay * attempt)  # —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É
                else:
                    logger.error(f"[get_cookies] –í—Å–µ {max_retries} –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å")
                    return None

    def save_cookies(self) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç cookies –∏–∑ requests.Session –≤ JSON-—Ñ–∞–π–ª."""
        with open("cookies.json", "w") as f:
            json.dump(self.session.cookies.get_dict(), f)

    def load_cookies(self) -> None:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç cookies –∏–∑ JSON-—Ñ–∞–π–ª–∞ –≤ requests.Session."""
        try:
            with open("cookies.json", "r") as f:
                cookies = json.load(f)
                jar = RequestsCookieJar()
                for k, v in cookies.items():
                    jar.set(k, v)
                self.session.cookies.update(jar)
        except FileNotFoundError:
            pass
    def fetch_data(self, url: str, retries: int = 5, backoff_factor: float = 1) -> str | None:
        proxy_data = None
        if self.proxy_obj:
            proxy_data = {"https": f"http://{self.proxy_obj.proxy_string}"}

        for attempt in range(1, retries + 1):
            if self.stop_event and self.stop_event.is_set():
                return

            # üöÄ –ü–†–û–§–ò–õ–ê–ö–¢–ò–ß–ï–°–ö–ê–Ø –°–ú–ï–ù–ê IP
            self.requests_count += 1
            self.proxy_requests_count += 1
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–∫—Å–∏
            if self.proxy_requests_count >= self.max_requests_per_ip:
                logger.info(f"üìä –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ –ø—Ä–æ–∫—Å–∏ ({self.max_requests_per_ip}) - —Ä–æ—Ç–∞—Ü–∏—è –ø—Ä–æ–∫—Å–∏")
                if getattr(self.config, 'proxy_rotation_enabled', True) and len(self.mobile_proxies) > 1:
                    # –ü—Ä–æ–±—É–µ–º —Ä–æ—Ç–∞—Ü–∏—é –ø—Ä–æ–∫—Å–∏
                    if self.rotate_proxy():
                        # –û–±–Ω–æ–≤–ª—è–µ–º proxy_data –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–∫—Å–∏
                        if self.proxy_obj:
                            proxy_data = {"https": f"http://{self.proxy_obj.proxy_string}"}
                        # –û–±–Ω–æ–≤–ª—è–µ–º cookies –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–∫—Å–∏
                        self.cookies = self.get_cookies(max_retries=2)
                    else:
                        # –ï—Å–ª–∏ —Ä–æ—Ç–∞—Ü–∏—è –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞, –º–µ–Ω—è–µ–º IP –Ω–∞ —Ç–µ–∫—É—â–µ–º –ø—Ä–æ–∫—Å–∏
                        self.change_ip(max_attempts=2)
                else:
                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Å–º–µ–Ω–∞ IP –µ—Å–ª–∏ —Ä–æ—Ç–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞
                    self.change_ip(max_attempts=2)

            try:
                response = self.session.get(
                    url=url,
                    headers=HEADERS,
                    proxies=proxy_data,
                    cookies=self.cookies,
                    timeout=30,
                    verify=False,
                    allow_redirects=True
                )
                logger.debug(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt}: {response.status_code}")
                
                # ‚úÖ –£–°–ü–ï–®–ù–´–ô –ó–ê–ü–†–û–° - —Å–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –Ω–µ—É–¥–∞—á
                if response.status_code == 200:
                    self.failed_requests_count = 0
                    self.save_cookies()
                    return response.text
                
                # üö® –ê–ì–†–ï–°–°–ò–í–ù–ê–Ø –†–ï–ê–ö–¶–ò–Ø –ù–ê –ü–†–û–ë–õ–ï–ú–´
                if response.status_code >= 500:
                    logger.warning(f"üî• –û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ {response.status_code} - –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–∞—è —Å–º–µ–Ω–∞ IP!")
                    self.change_ip(max_attempts=3)
                    raise RequestsError(f"–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {response.status_code}")
                
                if response.status_code == 429:
                    logger.warning(f"üö´ Rate limit {response.status_code} - —ç–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è —Å–º–µ–Ω–∞ IP!")
                    self.failed_requests_count += 1
                    # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Å–º–µ–Ω–∞ IP –ø—Ä–∏ rate limiting
                    for _ in range(2):  # –ú–µ–Ω—è–µ–º IP –¥–≤–∞–∂–¥—ã –ø–æ–¥—Ä—è–¥
                        self.change_ip(max_attempts=2)
                        time.sleep(random.randint(3, 8))
                    raise RequestsError(f"–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {response.status_code}")
                
                if response.status_code in [403, 302, 401, 422]:
                    logger.warning(f"üõ°Ô∏è –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ {response.status_code} - —Å—Ä–æ—á–Ω–∞—è —Å–º–µ–Ω–∞ IP –∏ cookies!")
                    self.failed_requests_count += 1
                    # –ü—Ä–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–µ - —Ç—Ä–æ–π–Ω–∞—è —Å–º–µ–Ω–∞ IP
                    for i in range(3):
                        logger.info(f"üîÑ –°–º–µ–Ω–∞ IP #{i+1} –ø—Ä–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–µ...")
                        self.change_ip(max_attempts=2)
                        time.sleep(random.randint(1, 5))
                    raise RequestsError(f"–ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω: {response.status_code}")

                # –õ—é–±–æ–π –¥—Ä—É–≥–æ–π –Ω–µ-200 —Å—Ç–∞—Ç—É—Å
                logger.warning(f"‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å {response.status_code} - —Å–º–µ–Ω–∞ IP")
                self.failed_requests_count += 1
                if self.failed_requests_count >= 2:  # –ü–æ—Å–ª–µ 2 –Ω–µ—É–¥–∞—á –ø–æ–¥—Ä—è–¥
                    self.change_ip(max_attempts=2)
                raise RequestsError(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å: {response.status_code}")
                
            except (RequestsError, Exception) as e:
                error_msg = str(e)
                logger.debug(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt} –∑–∞–∫–æ–Ω—á–∏–ª–∞—Å—å –Ω–µ—É—Å–ø–µ—à–Ω–æ: {error_msg}")
                
                # üî• –ê–ì–†–ï–°–°–ò–í–ù–ê–Ø –†–ï–ê–ö–¶–ò–Ø –ù–ê –°–ï–¢–ï–í–´–ï –û–®–ò–ë–ö–ò
                if any(keyword in error_msg.upper() for keyword in ["SSL", "TIMEOUT", "CONNECTION", "PROXY"]):
                    logger.warning(f"üåê –°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ - –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Å–º–µ–Ω–∞ IP: {error_msg[:100]}")
                    self.change_ip(max_attempts=2)
                    sleep_time = backoff_factor * attempt * 3  # –£–≤–µ–ª–∏—á–µ–Ω–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
                else:
                    sleep_time = backoff_factor * attempt
                
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –Ω–µ—É–¥–∞—á
                self.failed_requests_count += 1
                
                # –ü—Ä–∏ 3+ –Ω–µ—É–¥–∞—á–∞—Ö –ø–æ–¥—Ä—è–¥ - —ç–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è —Å–º–µ–Ω–∞ IP
                if self.failed_requests_count >= 3:
                    logger.error("üí• –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –Ω–µ—É–¥–∞—á –ø–æ–¥—Ä—è–¥ - —ç–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è —Å–º–µ–Ω–∞ IP!")
                    self.change_ip(max_attempts=3)
                    self.failed_requests_count = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø–æ—Å–ª–µ —Å–º–µ–Ω—ã
                
                if attempt < retries:
                    logger.debug(f"‚è≥ –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {sleep_time} —Å–µ–∫—É–Ω–¥...")
                    time.sleep(sleep_time)
                else:
                    logger.error(f"üíÄ –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ—É—Å–ø–µ—à–Ω—ã. –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–º–µ–Ω–∞ IP...")
                    self.change_ip(max_attempts=2)
                    return None

    def parse(self):
        self.load_cookies()
        cycle_count = 0  # –°—á–µ—Ç—á–∏–∫ —Ü–∏–∫–ª–æ–≤ –¥–ª—è –ø—Ä–æ–∞–∫—Ç–∏–≤–Ω–æ–π —Ä–æ—Ç–∞—Ü–∏–∏
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ñ–∏–ª–∏ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        profiles = self.db.conn.execute("SELECT id, client_id, client_secret, token FROM profiles").fetchall()
        for profile in profiles:
            profile_id, client_id, client_secret, token = profile
            # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ—Ñ–∏–ª—è —Å –Ω–æ–≤—ã–º–∏ –ø–æ–ª—è–º–∏
            ads = self.db.conn.execute("SELECT id, category, max_price, target_place_start, target_place_end, comment, url FROM ads WHERE profile_id = ? AND active = TRUE", (profile_id,)).fetchall()
            for ad in ads:
                print("–ù–æ–≤–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è —Ü–∏–∫–ª–∞ ad in ads")
                
                # üîÑ –ü–†–û–ê–ö–¢–ò–í–ù–ê–Ø –†–û–¢–ê–¶–ò–Ø –ü–†–û–ö–°–ò
                cycle_count += 1
                if (cycle_count % 3 == 0 and 
                    getattr(self.config, 'proxy_rotation_enabled', True) and 
                    len(self.mobile_proxies) > 1):
                    logger.info(f"üîÑ –ü—Ä–æ–∞–∫—Ç–∏–≤–Ω–∞—è —Ä–æ—Ç–∞—Ü–∏—è –ø—Ä–æ–∫—Å–∏ –∫–∞–∂–¥—ã–µ 3 —Ü–∏–∫–ª–∞ (—Ü–∏–∫–ª #{cycle_count})")
                    if self.rotate_proxy():
                        # –û–±–Ω–æ–≤–ª—è–µ–º cookies –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–∫—Å–∏
                        self.cookies = self.get_cookies(max_retries=2)
                
                ad_id, category, max_price, target_place_start, target_place_end, comment, url = ad
                # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ü–µ–Ω—É –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏–∑ ad_stats (int)
                last_stat = self.db.conn.execute(
                    "SELECT price FROM ad_stats WHERE ad_id = ? ORDER BY timestamp DESC LIMIT 1",
                    (ad_id,)
                ).fetchone()
                if last_stat and last_stat[0] is not None:
                    price_of_view = int(last_stat[0])
                    print("–ü–æ—Å–ª–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –Ω–∞–π–¥–µ–Ω–∞:", price_of_view)
                else:
                    print("–ü–æ—Å–ª–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–∞–≤–∫–∞")
                    bid_info = get_bid_info(token, ad_id)
                    if bid_info and bid_info.get('manual', {}).get('minBidPenny') is not None:
                        price_of_view = bid_info.get('manual', {}).get('minBidPenny')
                    else:
                        price_of_view = 0 # –∏–ª–∏ –¥—Ä—É–≥–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                current_index = 0
                target_id = ad_id
                for pages in range(1, 3):
                    print("–°—Ç—Ä–∞–Ω–∏—Ü–∞:", pages)
                    if self.stop_event and self.stop_event.is_set():
                        return
                    time.sleep(random.uniform(2.0, 4.0))
                    
                    html_code = self.fetch_data(url=category, retries=self.config.max_count_of_retry)
                    if not html_code:
                        break
                    data_from_page = self.find_json_on_page(html_code=html_code)
                    try:
                        # print(data_from_page)
                        ads_models = ItemsResponse(**data_from_page.get("catalog", {}))
                    except ValidationError as err:
                        logger.error(f"–ü—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {err}")
                        break
                    
                    ads_list = self._clean_null_ads(ads=ads_models.items)
                    current_index = self.find_place_of_target_ad(target_id, ads_list)
                    print("Targetid: ", target_id)
                    print("currentIndex: ", current_index)
                    if current_index != 0:
                        print("–ó–∞–ø–∏—Å—å –æ–±—ä—è–≤–ª–µ–Ω–∏—è –≤ –±–¥")
                        self.db.insert_ad_stat(ad_id, price_of_view, current_index)
                        break
                    if pages == 2:
                        print("–û–±—ä—è–≤–ª–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∞ –ø–µ—Ä–≤—ã—Ö 2 —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö")
                        self.db.insert_ad_stat(ad_id, price_of_view, 100)
                        break
                    url = self.get_next_page_url(url=url)
    @staticmethod
    def _clean_null_ads(ads: list[Item]) -> list[Item]:
        return [ad for ad in ads if ad.id]
    @staticmethod
    def find_place_of_target_ad(target_id, ads):
        for i, ad in enumerate(ads):
            # print("Id of ad: ", ad.id)
            if str(ad.id) == str(target_id): return i + 1
        return 0
    @staticmethod
    def extarct_ad_id(s):
        return s[:s.index('?')].split('_')[-1] if '?' in s else s.split('_')[-1]
    @staticmethod
    def find_json_on_page(html_code, data_type: str = "mime") -> dict:
        soup = BeautifulSoup(html_code, "html.parser")
        try:
            for _script in soup.select('script'):
                if data_type == 'mime':
                    if _script.get('type') == 'mime/invalid' and _script.get(
                            'data-mfe-state') == 'true':  # and 'sandbox' not in _script.text:
                        mime_data = json.loads(html.unescape(_script.text)).get('data', {})
                        return mime_data

        except Exception as err:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {err}")
        return {}


    def change_ip(self, max_attempts: int = 3) -> bool:
        """–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è —Å–º–µ–Ω–∞ IP —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –∏ —Ä–æ—Ç–∞—Ü–∏–µ–π –ø—Ä–æ–∫—Å–∏"""
        if not self.mobile_proxies:
            logger.warning("‚ö†Ô∏è –°–º–µ–Ω–∞ IP –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞ - –º–æ–±–∏–ª—å–Ω—ã–µ –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã")
            return False
        
        current_proxy = self.mobile_proxies[self.current_proxy_index]
        logger.info(f"üîÑ –ù–∞—á–∏–Ω–∞—é –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—É—é —Å–º–µ–Ω—É IP –¥–ª—è –ø—Ä–æ–∫—Å–∏ {current_proxy.name}...")
        
        # –ü—Ä–æ–±—É–µ–º —Å–º–µ–Ω–∏—Ç—å IP –Ω–∞ —Ç–µ–∫—É—â–µ–º –ø—Ä–æ–∫—Å–∏
        for attempt in range(1, max_attempts + 1):
            try:
                logger.info(f"üéØ –ü–æ–ø—ã—Ç–∫–∞ —Å–º–µ–Ω—ã IP {attempt}/{max_attempts} –Ω–∞ –ø—Ä–æ–∫—Å–∏ {current_proxy.name}")
                res = requests.get(
                    url=current_proxy.proxy_change_url, 
                    timeout=20,
                    verify=False
                )
                
                if res.status_code == 200:
                    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫–∏ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π —Å–º–µ–Ω—ã IP
                    self.requests_count = 0
                    self.failed_requests_count = 0
                    self.proxy_requests_count = 0
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –Ω–æ–≤–æ–≥–æ IP
                    wait_time = random.randint(1, 5)
                    logger.info(f"‚úÖ IP —É—Å–ø–µ—à–Ω–æ –∏–∑–º–µ–Ω–µ–Ω –Ω–∞ –ø—Ä–æ–∫—Å–∏ {current_proxy.name}! –ü–∞—É–∑–∞ {wait_time} —Å–µ–∫ –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏")
                    time.sleep(wait_time)
                    
                    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º cookies —Å –Ω–æ–≤—ã–º IP
                    logger.info("üç™ –û–±–Ω–æ–≤–ª—è—é cookies —Å –Ω–æ–≤—ã–º IP...")
                    self.cookies = self.get_cookies(max_retries=2)
                    return True
                else:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–º–µ–Ω—ã IP –Ω–∞ –ø—Ä–æ–∫—Å–∏ {current_proxy.name}: —Å—Ç–∞—Ç—É—Å {res.status_code}")
                    
            except Exception as err:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–º–µ–Ω–µ IP –Ω–∞ –ø—Ä–æ–∫—Å–∏ {current_proxy.name} (–ø–æ–ø—ã—Ç–∫–∞ {attempt}): {err}")
            
            if attempt < max_attempts:
                wait_time = random.randint(1, 2) * attempt
                logger.info(f"‚è≥ –ü–æ–≤—Ç–æ—Ä —Å–º–µ–Ω—ã IP —á–µ—Ä–µ–∑ {wait_time} —Å–µ–∫—É–Ω–¥...")
                time.sleep(wait_time)
        
        # –ï—Å–ª–∏ —Å–º–µ–Ω–∞ IP –Ω–∞ —Ç–µ–∫—É—â–µ–º –ø—Ä–æ–∫—Å–∏ –Ω–µ —É–¥–∞–ª–∞—Å—å, –ø—Ä–æ–±—É–µ–º —Ä–æ—Ç–∞—Ü–∏—é –ø—Ä–æ–∫—Å–∏
        logger.warning("üí• –°–º–µ–Ω–∞ IP –Ω–∞ —Ç–µ–∫—É—â–µ–º –ø—Ä–æ–∫—Å–∏ –Ω–µ —É–¥–∞–ª–∞—Å—å, –ø—Ä–æ–±—É–µ–º —Ä–æ—Ç–∞—Ü–∏—é –ø—Ä–æ–∫—Å–∏...")
        
        if len(self.mobile_proxies) > 1 and getattr(self.config, 'proxy_switch_on_error', True):
            if self.rotate_proxy():
                logger.info("üîÑ –ü—Ä–æ–∫—Å–∏ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω, –ø—Ä–æ–±—É–µ–º —Å–º–µ–Ω—É IP –Ω–∞ –Ω–æ–≤–æ–º –ø—Ä–æ–∫—Å–∏...")
                
                # –ü—Ä–æ–±—É–µ–º —Å–º–µ–Ω–∏—Ç—å IP –Ω–∞ –Ω–æ–≤–æ–º –ø—Ä–æ–∫—Å–∏ (1 –ø–æ–ø—ã—Ç–∫–∞)
                new_proxy = self.mobile_proxies[self.current_proxy_index]
                try:
                    res = requests.get(
                        url=new_proxy.proxy_change_url, 
                        timeout=20,
                        verify=False
                    )
                    
                    if res.status_code == 200:
                        self.requests_count = 0
                        self.failed_requests_count = 0
                        self.proxy_requests_count = 0
                        
                        wait_time = random.randint(1, 5)
                        logger.info(f"‚úÖ IP —É—Å–ø–µ—à–Ω–æ –∏–∑–º–µ–Ω–µ–Ω –Ω–∞ –Ω–æ–≤–æ–º –ø—Ä–æ–∫—Å–∏ {new_proxy.name}! –ü–∞—É–∑–∞ {wait_time} —Å–µ–∫")
                        time.sleep(wait_time)
                        
                        self.cookies = self.get_cookies(max_retries=2)
                        return True
                except Exception as err:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–º–µ–Ω—ã IP –Ω–∞ –Ω–æ–≤–æ–º –ø—Ä–æ–∫—Å–∏ {new_proxy.name}: {err}")
        
        logger.error("üí• –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ —Å–º–µ–Ω—ã IP –∏ —Ä–æ—Ç–∞—Ü–∏–∏ –ø—Ä–æ–∫—Å–∏ –Ω–µ—É—Å–ø–µ—à–Ω—ã!")
        # –î–∞–∂–µ –µ—Å–ª–∏ —Å–º–µ–Ω–∞ IP –Ω–µ —É–¥–∞–ª–∞—Å—å, –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º cookies
        logger.info("üÜò –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ cookies...")
        self.cookies = self.get_cookies(max_retries=1)
        return False

    @staticmethod
    def get_next_page_url(url: str):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É"""
        try:
            url_parts = urlparse(url)
            query_params = parse_qs(url_parts.query)
            current_page = int(query_params.get('p', [1])[0])
            query_params['p'] = current_page + 1

            new_query = urlencode(query_params, doseq=True)
            next_url = urlunparse((url_parts.scheme, url_parts.netloc, url_parts.path, url_parts.params, new_query,
                                   url_parts.fragment))
            return next_url
        except Exception as err:
            logger.error(f"–ù–µ —Å–º–æ–≥ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è {url}. –û—à–∏–±–∫–∞: {err}")

import requests  # —É–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è curl_cffi.requests –≤—ã—à–µ; —ç—Ç–æ—Ç –∏–º–ø–æ—Ä—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –ª–∏—à–Ω–∏–º –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ requests, –æ—Å—Ç–∞–≤–ª–µ–Ω –µ—Å–ª–∏ –≥–¥–µ-—Ç–æ –Ω—É–∂–µ–Ω



if __name__ == "__main__":
    print("–ó–∞–ø—É—Å–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–¥")
    init_db_from_config()
    print("–£—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    # –°—á–µ—Ç—á–∏–∫ –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Å–º–µ–Ω—ã IP
    cycle_count = 0
    ip_change_interval = 3  # –ú–µ–Ω—è–µ–º IP –∫–∞–∂–¥—ã–µ 3 —Ü–∏–∫–ª–∞
    
    while True:
        try:
            config = load_avito_config("config.json")
            parser = AvitoParse(config)
            
            #  –ü–†–û–§–ò–õ–ê–ö–¢–ò–ß–ï–°–ö–ê–Ø –°–ú–ï–ù–ê IP –ü–ï–†–ï–î –ü–ê–†–°–ò–ù–ì–û–ú
            cycle_count += 1
            if cycle_count % ip_change_interval == 0:
                logger.info(f"üîÑ –ü—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Å–º–µ–Ω–∞ IP (—Ü–∏–∫–ª #{cycle_count})")
                parser.change_ip(max_attempts=2)
            
            parser.parse()
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–∞—É–∑—É (–∑–∞—â–∏—Ç–∞ –æ—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö/None –∑–Ω–∞—á–µ–Ω–∏–π, –≤—ã–∑—ã–≤–∞—é—â–∏—Ö OSError: [Errno 22] Invalid argument)
            raw_pause = getattr(config, 'pause_general', 60)
            try:
                pause_val = int(raw_pause)
            except Exception:
                pause_val = 60
            if pause_val < 0:
                logger.warning(f"–ü–æ–ª—É—á–µ–Ω–æ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ pause_general={raw_pause}. –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º 30 —Å–µ–∫")
                pause_val = 30

            logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –ü–∞—É–∑–∞ {pause_val} —Å–µ–∫")
            print("Updating prices")
            check_and_update_prices()
            
            # –ü–†–û–§–ò–õ–ê–ö–¢–ò–ß–ï–°–ö–ê–Ø –°–ú–ï–ù–ê IP –ü–û–°–õ–ï –û–ë–ù–û–í–õ–ï–ù–ò–Ø –¶–ï–ù
            if cycle_count % (ip_change_interval * 2) == 0:  # –ö–∞–∂–¥—ã–µ 6 —Ü–∏–∫–ª–æ–≤
                logger.info("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å–º–µ–Ω–∞ IP –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ü–µ–Ω")
                parser.change_ip(max_attempts=1)
            
            try:
                time.sleep(pause_val)
            except OSError as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–Ω–∞ (pause={pause_val}): {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø–∞—Å–Ω—É—é –ø–∞—É–∑—É 30 —Å–µ–∫")
                time.sleep(30)
            
        except Exception as err:
            # –ü–æ–ª–Ω—ã–π traceback –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
            logger.exception(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ: {err}")
            error_msg = str(err)
            
            #  –≠–ö–°–¢–†–ï–ù–ù–ê–Ø –°–ú–ï–ù–ê IP –ü–†–ò –û–®–ò–ë–ö–ê–•
            try:
                if config and hasattr(config, 'proxy_change_url') and config.proxy_change_url:
                    logger.warning("–≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è —Å–º–µ–Ω–∞ IP –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏")
                    emergency_parser = AvitoParse(config)
                    emergency_parser.change_ip(max_attempts=3)
            except:
                pass
            
            # –î–ª—è SSL –æ—à–∏–±–æ–∫ –¥–µ–ª–∞–µ–º –±–æ–ª–µ–µ –¥–ª–∏—Ç–µ–ª—å–Ω—É—é –ø–∞—É–∑—É
            if any(keyword in error_msg for keyword in ["SSL", "UNEXPECTED_EOF", "Max retries exceeded", "Connection"]):
                logger.warning("üåê –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ–º, —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–∞—É–∑—É –¥–æ 90 —Å–µ–∫—É–Ω–¥")
                time.sleep(90)
            else:
                time.sleep(30)
